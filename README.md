# WebLogs

Формат файлов с логами:<br>
 %h %t \"%r\" %>s %b \"%{Referer}i\" \"%{User-Agent}i\" %D<br>
 %h - имя удаленного хоста<br>
 %t - время получения запроса<br>
 %r - тип запроса, его содержимое и версия<br>
 %s - код состояния HTTP<br>
 %b - количество отданных сервером байт<br>
 %{Referer} - URL-источник запроса<br>
 %{User-Agent} - HTTP-заголовок, содержащий информацию о запросе<br>
 %D - длительность запроса в микросекундах<br>

<h3>Использование:</h3> 
    python main.py --path "путь к файлу или папке с файлами логов с расширением *.log"<br>
    далее происходит поиск файлов с расширением *.log
    парсится лог по регулярному выражению: r"(?P<ip>.*?) (?P<remote_log_name>.*?) (?P<userid>.*?) \[(?P<date>.*?)(?= ) " \
            r"(?P<timezone>.*?)\] \"(?P<request_method>.*?) (?P<path>.*?) (?P<request_version>HTTP/.*)?\" " \
            r"(?P<status>.*?) (?P<length>.*?) \"(?P<referrer>.*?)\" \"(?P<user_agent>.*)\" " \
            r"(?P<generation_time_micro>.*)"
    далее происходит отбор по требуемым условиям (так как скрипт изначально выполнялся очень долго, была использована библиотека pandas)
    после выполнения скрипта создается папка "results", в которой сохраняются файлы json для обработанных файлов логов в формате:<br>
        общее количество выполненных запросов<br>
        количество запросов по типу: GET - 20, POST - 10 и т.п.<br>
        топ 3 IP адресов, с которых были сделаны запросы<br>
        топ 3 самых долгих запросов, должно быть видно метод, url, ip, время запроса
